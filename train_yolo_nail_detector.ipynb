{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# YOLO Nail Detection Model Training\n",
        "\n",
        "This notebook trains a custom YOLO model specifically for nail detection in hand images.\n",
        "\n",
        "## Prerequisites\n",
        "\n",
        "Before training, you need:\n",
        "1. **Annotated dataset** with bounding boxes around nails in hand images\n",
        "2. **YOLO format annotations** (`.txt` files with normalized coordinates)\n",
        "3. **Organized directory structure** (see Data Preparation section)\n",
        "\n",
        "## Data Requirements\n",
        "\n",
        "- **Images**: Hand images containing visible nails\n",
        "- **Annotations**: One `.txt` file per image with bounding box coordinates\n",
        "- **Format**: YOLO format (normalized: class_id x_center y_center width height)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "%pip install ultralytics opencv-python pillow matplotlib\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Data Preparation\n",
        "\n",
        "### Directory Structure\n",
        "\n",
        "Your dataset should be organized as follows:\n",
        "\n",
        "```\n",
        "yolo_nail_dataset/\n",
        "‚îú‚îÄ‚îÄ train/\n",
        "‚îÇ   ‚îú‚îÄ‚îÄ images/\n",
        "‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ image1.jpg\n",
        "‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ image2.jpg\n",
        "‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...\n",
        "‚îÇ   ‚îî‚îÄ‚îÄ labels/\n",
        "‚îÇ       ‚îú‚îÄ‚îÄ image1.txt\n",
        "‚îÇ       ‚îú‚îÄ‚îÄ image2.txt\n",
        "‚îÇ       ‚îî‚îÄ‚îÄ ...\n",
        "‚îú‚îÄ‚îÄ val/\n",
        "‚îÇ   ‚îú‚îÄ‚îÄ images/\n",
        "‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ val1.jpg\n",
        "‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...\n",
        "‚îÇ   ‚îî‚îÄ‚îÄ labels/\n",
        "‚îÇ       ‚îú‚îÄ‚îÄ val1.txt\n",
        "‚îÇ       ‚îî‚îÄ‚îÄ ...\n",
        "‚îî‚îÄ‚îÄ test/  (optional)\n",
        "    ‚îú‚îÄ‚îÄ images/\n",
        "    ‚îî‚îÄ‚îÄ labels/\n",
        "```\n",
        "\n",
        "### YOLO Annotation Format\n",
        "\n",
        "Each `.txt` file should contain one line per nail detection:\n",
        "```\n",
        "class_id x_center y_center width height\n",
        "```\n",
        "\n",
        "Where:\n",
        "- `class_id`: 0 (for nail class - single class detection)\n",
        "- All coordinates are **normalized** (0.0 to 1.0)\n",
        "- `x_center, y_center`: Center of bounding box (normalized)\n",
        "- `width, height`: Width and height of bounding box (normalized)\n",
        "\n",
        "**Example annotation** (`image1.txt`):\n",
        "```\n",
        "0 0.5 0.3 0.1 0.15\n",
        "0 0.7 0.3 0.1 0.15\n",
        "```\n",
        "This means 2 nails detected in the image.\n",
        "\n",
        "### Annotation Tools\n",
        "\n",
        "You can use tools like:\n",
        "- **LabelImg**: https://github.com/HumanSignal/labelImg\n",
        "- **Roboflow**: https://roboflow.com/\n",
        "- **CVAT**: https://cvat.org/\n",
        "- **Label Studio**: https://labelstud.io/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import yaml\n",
        "from pathlib import Path\n",
        "from ultralytics import YOLO\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Configuration\n",
        "DATASET_DIR = \"yolo_nail_dataset\"  # Change this to your dataset path\n",
        "MODEL_SIZE = \"n\"  # Options: n (nano), s (small), m (medium), l (large), x (xlarge)\n",
        "EPOCHS = 100\n",
        "IMG_SIZE = 640\n",
        "BATCH_SIZE = 16\n",
        "PATIENCE = 50  # Early stopping patience\n",
        "\n",
        "# Output directory\n",
        "OUTPUT_DIR = \"runs/detect/nail-detector\"\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "print(\"Configuration loaded!\")\n",
        "print(f\"Model size: YOLOv8{MODEL_SIZE}\")\n",
        "print(f\"Epochs: {EPOCHS}\")\n",
        "print(f\"Image size: {IMG_SIZE}\")\n",
        "print(f\"Batch size: {BATCH_SIZE}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Create Dataset Configuration\n",
        "\n",
        "We need to create a `dataset.yaml` file that YOLO uses to locate the training data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create dataset.yaml configuration file\n",
        "dataset_config = {\n",
        "    'path': os.path.abspath(DATASET_DIR),  # Absolute path to dataset\n",
        "    'train': 'train/images',  # Relative to 'path'\n",
        "    'val': 'val/images',      # Relative to 'path'\n",
        "    'test': 'test/images' if os.path.exists(os.path.join(DATASET_DIR, 'test')) else None,  # Optional\n",
        "    \n",
        "    # Class names\n",
        "    'names': {\n",
        "        0: 'nail'\n",
        "    },\n",
        "    \n",
        "    # Number of classes\n",
        "    'nc': 1\n",
        "}\n",
        "\n",
        "# Save configuration\n",
        "yaml_path = os.path.join(DATASET_DIR, 'dataset.yaml')\n",
        "with open(yaml_path, 'w') as f:\n",
        "    yaml.dump(dataset_config, f, default_flow_style=False, sort_keys=False)\n",
        "\n",
        "print(f\"Dataset configuration saved to: {yaml_path}\")\n",
        "print(\"\\nConfiguration:\")\n",
        "print(yaml.dump(dataset_config, default_flow_style=False))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Verify Dataset Structure\n",
        "\n",
        "Let's verify that your dataset is properly organized before training.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def verify_dataset(dataset_dir):\n",
        "    \"\"\"Verify dataset structure and annotations\"\"\"\n",
        "    issues = []\n",
        "    warnings = []\n",
        "    \n",
        "    # Check directory structure\n",
        "    train_img_dir = os.path.join(dataset_dir, 'train', 'images')\n",
        "    train_label_dir = os.path.join(dataset_dir, 'train', 'labels')\n",
        "    val_img_dir = os.path.join(dataset_dir, 'val', 'images')\n",
        "    val_label_dir = os.path.join(dataset_dir, 'val', 'labels')\n",
        "    \n",
        "    # Check if directories exist\n",
        "    for dir_path, name in [(train_img_dir, 'train/images'), \n",
        "                           (train_label_dir, 'train/labels'),\n",
        "                           (val_img_dir, 'val/images'),\n",
        "                           (val_label_dir, 'val/labels')]:\n",
        "        if not os.path.exists(dir_path):\n",
        "            issues.append(f\"Missing directory: {name}\")\n",
        "        else:\n",
        "            print(f\"‚úì Found: {name}\")\n",
        "    \n",
        "    if issues:\n",
        "        print(\"\\n‚ùå Issues found:\")\n",
        "        for issue in issues:\n",
        "            print(f\"  - {issue}\")\n",
        "        return False\n",
        "    \n",
        "    # Count files\n",
        "    train_images = [f for f in os.listdir(train_img_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))] if os.path.exists(train_img_dir) else []\n",
        "    train_labels = [f for f in os.listdir(train_label_dir) if f.endswith('.txt')] if os.path.exists(train_label_dir) else []\n",
        "    \n",
        "    val_images = [f for f in os.listdir(val_img_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))] if os.path.exists(val_img_dir) else []\n",
        "    val_labels = [f for f in os.listdir(val_label_dir) if f.endswith('.txt')] if os.path.exists(val_label_dir) else []\n",
        "    \n",
        "    print(f\"\\nüìä Dataset Statistics:\")\n",
        "    print(f\"  Training images: {len(train_images)}\")\n",
        "    print(f\"  Training labels: {len(train_labels)}\")\n",
        "    print(f\"  Validation images: {len(val_images)}\")\n",
        "    print(f\"  Validation labels: {len(val_labels)}\")\n",
        "    \n",
        "    # Check for matching files\n",
        "    train_img_names = {os.path.splitext(f)[0] for f in train_images}\n",
        "    train_label_names = {os.path.splitext(f)[0] for f in train_labels}\n",
        "    \n",
        "    missing_labels = train_img_names - train_label_names\n",
        "    missing_images = train_label_names - train_img_names\n",
        "    \n",
        "    if missing_labels:\n",
        "        warnings.append(f\"‚ö†Ô∏è  {len(missing_labels)} training images without labels\")\n",
        "    if missing_images:\n",
        "        warnings.append(f\"‚ö†Ô∏è  {len(missing_images)} training labels without images\")\n",
        "    \n",
        "    if warnings:\n",
        "        print(\"\\n‚ö†Ô∏è  Warnings:\")\n",
        "        for warning in warnings:\n",
        "            print(f\"  - {warning}\")\n",
        "    \n",
        "    # Validate annotation format\n",
        "    if train_labels:\n",
        "        sample_label = os.path.join(train_label_dir, train_labels[0])\n",
        "        try:\n",
        "            with open(sample_label, 'r') as f:\n",
        "                lines = f.readlines()\n",
        "                if lines:\n",
        "                    parts = lines[0].strip().split()\n",
        "                    if len(parts) == 5:\n",
        "                        class_id, x, y, w, h = map(float, parts)\n",
        "                        if 0 <= x <= 1 and 0 <= y <= 1 and 0 <= w <= 1 and 0 <= h <= 1:\n",
        "                            print(f\"\\n‚úì Sample annotation format is correct: {train_labels[0]}\")\n",
        "                        else:\n",
        "                            issues.append(\"Annotation coordinates not normalized (should be 0-1)\")\n",
        "                    else:\n",
        "                        issues.append(f\"Invalid annotation format in {train_labels[0]} (expected 5 values)\")\n",
        "        except Exception as e:\n",
        "            issues.append(f\"Error reading annotation: {e}\")\n",
        "    \n",
        "    if not issues:\n",
        "        print(\"\\n‚úÖ Dataset structure looks good!\")\n",
        "        return True\n",
        "    else:\n",
        "        print(\"\\n‚ùå Please fix the issues above before training.\")\n",
        "        return False\n",
        "\n",
        "# Verify dataset\n",
        "if os.path.exists(DATASET_DIR):\n",
        "    verify_dataset(DATASET_DIR)\n",
        "else:\n",
        "    print(f\"‚ùå Dataset directory not found: {DATASET_DIR}\")\n",
        "    print(\"\\nPlease create the dataset directory with the following structure:\")\n",
        "    print(\"yolo_nail_dataset/\")\n",
        "    print(\"  ‚îú‚îÄ‚îÄ train/\")\n",
        "    print(\"  ‚îÇ   ‚îú‚îÄ‚îÄ images/\")\n",
        "    print(\"  ‚îÇ   ‚îî‚îÄ‚îÄ labels/\")\n",
        "    print(\"  ‚îî‚îÄ‚îÄ val/\")\n",
        "    print(\"      ‚îú‚îÄ‚îÄ images/\")\n",
        "    print(\"      ‚îî‚îÄ‚îÄ labels/\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load pretrained YOLOv8 model\n",
        "model_name = f\"yolov8{MODEL_SIZE}.pt\"\n",
        "print(f\"Loading pretrained model: {model_name}\")\n",
        "\n",
        "model = YOLO(model_name)\n",
        "print(\"‚úì Model loaded successfully!\")\n",
        "\n",
        "# Display model info\n",
        "print(f\"\\nModel architecture: YOLOv8{MODEL_SIZE}\")\n",
        "print(f\"Parameters: {sum(p.numel() for p in model.model.parameters()):,}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Train the Model\n",
        "\n",
        "This will start the training process. Training may take a while depending on:\n",
        "- Number of images\n",
        "- Model size (n/s/m/l/x)\n",
        "- Hardware (CPU/GPU)\n",
        "- Number of epochs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training configuration\n",
        "train_args = {\n",
        "    'data': yaml_path,           # Path to dataset.yaml\n",
        "    'epochs': EPOCHS,            # Number of training epochs\n",
        "    'imgsz': IMG_SIZE,           # Image size\n",
        "    'batch': BATCH_SIZE,         # Batch size\n",
        "    'name': 'nail-detector',     # Project name\n",
        "    'patience': PATIENCE,        # Early stopping patience\n",
        "    'save': True,                # Save checkpoints\n",
        "    'save_period': 10,           # Save checkpoint every N epochs\n",
        "    'device': 0,                 # GPU device (0 for first GPU, 'cpu' for CPU)\n",
        "    'workers': 8,                # Number of data loading workers\n",
        "    'project': 'runs/detect',    # Project directory\n",
        "    'exist_ok': True,            # Overwrite existing project\n",
        "    'pretrained': True,          # Use pretrained weights\n",
        "    'optimizer': 'AdamW',        # Optimizer\n",
        "    'lr0': 0.01,                 # Initial learning rate\n",
        "    'lrf': 0.01,                 # Final learning rate (lr0 * lrf)\n",
        "    'momentum': 0.937,           # SGD momentum/Adam beta1\n",
        "    'weight_decay': 0.0005,      # Weight decay\n",
        "    'warmup_epochs': 3.0,        # Warmup epochs\n",
        "    'warmup_momentum': 0.8,      # Warmup initial momentum\n",
        "    'warmup_bias_lr': 0.1,       # Warmup initial bias lr\n",
        "    'box': 7.5,                  # Box loss gain\n",
        "    'cls': 0.5,                  # Class loss gain\n",
        "    'dfl': 1.5,                  # DFL loss gain\n",
        "    'hsv_h': 0.015,              # Image HSV-Hue augmentation\n",
        "    'hsv_s': 0.7,                # Image HSV-Saturation augmentation\n",
        "    'hsv_v': 0.4,                # Image HSV-Value augmentation\n",
        "    'degrees': 0.0,              # Image rotation (+/- deg)\n",
        "    'translate': 0.1,           # Image translation (+/- fraction)\n",
        "    'scale': 0.5,                # Image scale (+/- gain)\n",
        "    'shear': 0.0,                # Image shear (+/- deg)\n",
        "    'perspective': 0.0,          # Image perspective (+/- fraction)\n",
        "    'flipud': 0.0,               # Image flip up-down (probability)\n",
        "    'fliplr': 0.5,               # Image flip left-right (probability)\n",
        "    'mosaic': 1.0,               # Image mosaic (probability)\n",
        "    'mixup': 0.0,                # Image mixup (probability)\n",
        "    'copy_paste': 0.0,           # Segment copy-paste (probability)\n",
        "}\n",
        "\n",
        "print(\"Starting training...\")\n",
        "print(f\"Training for {EPOCHS} epochs\")\n",
        "print(f\"Dataset: {yaml_path}\")\n",
        "print(f\"Output: {OUTPUT_DIR}\")\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "\n",
        "# Start training\n",
        "results = model.train(**train_args)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"‚úÖ Training completed!\")\n",
        "print(f\"Best model saved to: {results.save_dir}/weights/best.pt\")\n",
        "print(f\"Last model saved to: {results.save_dir}/weights/last.pt\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Evaluate the Model\n",
        "\n",
        "Let's evaluate the trained model on the validation set.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the best model\n",
        "best_model_path = os.path.join(results.save_dir, 'weights', 'best.pt')\n",
        "print(f\"Loading best model from: {best_model_path}\")\n",
        "\n",
        "best_model = YOLO(best_model_path)\n",
        "\n",
        "# Evaluate on validation set\n",
        "metrics = best_model.val(data=yaml_path, imgsz=IMG_SIZE)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üìä Validation Results:\")\n",
        "print(\"=\"*60)\n",
        "print(f\"mAP50: {metrics.box.map50:.4f}\")\n",
        "print(f\"mAP50-95: {metrics.box.map:.4f}\")\n",
        "print(f\"Precision: {metrics.box.mp:.4f}\")\n",
        "print(f\"Recall: {metrics.box.mr:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Test on Sample Images\n",
        "\n",
        "Test the trained model on some sample images to visualize detections.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def visualize_predictions(model, image_path, conf_threshold=0.25, save_path=None):\n",
        "    \"\"\"Visualize model predictions on an image\"\"\"\n",
        "    # Run inference\n",
        "    results = model(image_path, conf=conf_threshold, imgsz=IMG_SIZE)\n",
        "    \n",
        "    # Get the first result\n",
        "    result = results[0]\n",
        "    \n",
        "    # Plot results\n",
        "    annotated_img = result.plot()\n",
        "    \n",
        "    # Convert BGR to RGB for matplotlib\n",
        "    annotated_img_rgb = cv2.cvtColor(annotated_img, cv2.COLOR_BGR2RGB)\n",
        "    \n",
        "    plt.figure(figsize=(12, 8))\n",
        "    plt.imshow(annotated_img_rgb)\n",
        "    plt.axis('off')\n",
        "    plt.title(f'Nail Detection Results (conf ‚â• {conf_threshold})')\n",
        "    plt.tight_layout()\n",
        "    \n",
        "    if save_path:\n",
        "        cv2.imwrite(save_path, annotated_img)\n",
        "        print(f\"Saved visualization to: {save_path}\")\n",
        "    \n",
        "    plt.show()\n",
        "    \n",
        "    # Print detection info\n",
        "    if len(result.boxes) > 0:\n",
        "        print(f\"\\nDetected {len(result.boxes)} nail(s):\")\n",
        "        for i, box in enumerate(result.boxes):\n",
        "            conf = float(box.conf[0])\n",
        "            x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
        "            print(f\"  Nail {i+1}: confidence={conf:.3f}, bbox=({x1:.1f}, {y1:.1f}, {x2:.1f}, {y2:.1f})\")\n",
        "    else:\n",
        "        print(\"\\nNo nails detected.\")\n",
        "    \n",
        "    return result\n",
        "\n",
        "# Test on validation images (if available)\n",
        "val_img_dir = os.path.join(DATASET_DIR, 'val', 'images')\n",
        "if os.path.exists(val_img_dir):\n",
        "    val_images = [f for f in os.listdir(val_img_dir) \n",
        "                  if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
        "    \n",
        "    if val_images:\n",
        "        # Test on first validation image\n",
        "        test_image = os.path.join(val_img_dir, val_images[0])\n",
        "        print(f\"Testing on: {test_image}\")\n",
        "        visualize_predictions(best_model, test_image, conf_threshold=0.25)\n",
        "    else:\n",
        "        print(\"No validation images found for testing.\")\n",
        "else:\n",
        "    print(\"Validation image directory not found.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 8: Export and Save Model\n",
        "\n",
        "Save the trained model to a location where the Flask app can use it.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Copy best model to models directory for use in Flask app\n",
        "import shutil\n",
        "\n",
        "models_dir = \"models\"\n",
        "os.makedirs(models_dir, exist_ok=True)\n",
        "\n",
        "# Copy best model\n",
        "best_model_dest = os.path.join(models_dir, \"yolo_nail_detector_best.pt\")\n",
        "shutil.copy2(best_model_path, best_model_dest)\n",
        "\n",
        "print(f\"‚úÖ Best model copied to: {best_model_dest}\")\n",
        "print(f\"\\nTo use this model in your Flask app, update app.py:\")\n",
        "print(f\"  nail_detector = NailDetector(model_path='{best_model_dest}')\")\n",
        "\n",
        "# Also export to ONNX format (optional, for deployment)\n",
        "try:\n",
        "    onnx_path = os.path.join(models_dir, \"yolo_nail_detector.onnx\")\n",
        "    best_model.export(format='onnx', imgsz=IMG_SIZE)\n",
        "    print(f\"\\n‚úÖ Model exported to ONNX format\")\n",
        "except Exception as e:\n",
        "    print(f\"\\n‚ö†Ô∏è  ONNX export failed: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 9: Training Summary\n",
        "\n",
        "Review the training results and metrics.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display training curves\n",
        "results_dir = results.save_dir\n",
        "results_csv = os.path.join(results_dir, 'results.csv')\n",
        "\n",
        "if os.path.exists(results_csv):\n",
        "    import pandas as pd\n",
        "    \n",
        "    df = pd.read_csv(results_csv)\n",
        "    \n",
        "    # Plot training curves\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "    \n",
        "    # Loss curves\n",
        "    axes[0, 0].plot(df['epoch'], df['train/box_loss'], label='Train Box Loss', color='blue')\n",
        "    axes[0, 0].plot(df['epoch'], df['val/box_loss'], label='Val Box Loss', color='red')\n",
        "    axes[0, 0].set_xlabel('Epoch')\n",
        "    axes[0, 0].set_ylabel('Box Loss')\n",
        "    axes[0, 0].set_title('Box Loss')\n",
        "    axes[0, 0].legend()\n",
        "    axes[0, 0].grid(True)\n",
        "    \n",
        "    axes[0, 1].plot(df['epoch'], df['train/cls_loss'], label='Train Class Loss', color='blue')\n",
        "    axes[0, 1].plot(df['epoch'], df['val/cls_loss'], label='Val Class Loss', color='red')\n",
        "    axes[0, 1].set_xlabel('Epoch')\n",
        "    axes[0, 1].set_ylabel('Class Loss')\n",
        "    axes[0, 1].set_title('Class Loss')\n",
        "    axes[0, 1].legend()\n",
        "    axes[0, 1].grid(True)\n",
        "    \n",
        "    # mAP curves\n",
        "    axes[1, 0].plot(df['epoch'], df['metrics/mAP50(B)'], label='mAP50', color='green')\n",
        "    axes[1, 0].set_xlabel('Epoch')\n",
        "    axes[1, 0].set_ylabel('mAP50')\n",
        "    axes[1, 0].set_title('Mean Average Precision (mAP50)')\n",
        "    axes[1, 0].legend()\n",
        "    axes[1, 0].grid(True)\n",
        "    \n",
        "    axes[1, 1].plot(df['epoch'], df['metrics/mAP50-95(B)'], label='mAP50-95', color='purple')\n",
        "    axes[1, 1].set_xlabel('Epoch')\n",
        "    axes[1, 1].set_ylabel('mAP50-95')\n",
        "    axes[1, 1].set_title('Mean Average Precision (mAP50-95)')\n",
        "    axes[1, 1].legend()\n",
        "    axes[1, 1].grid(True)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Print best metrics\n",
        "    best_epoch = df['metrics/mAP50(B)'].idxmax()\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"üìà Best Training Metrics:\")\n",
        "    print(\"=\"*60)\n",
        "    print(f\"Best Epoch: {int(df.loc[best_epoch, 'epoch'])}\")\n",
        "    print(f\"Best mAP50: {df.loc[best_epoch, 'metrics/mAP50(B)']:.4f}\")\n",
        "    print(f\"Best mAP50-95: {df.loc[best_epoch, 'metrics/mAP50-95(B)']:.4f}\")\n",
        "    print(f\"Best Precision: {df.loc[best_epoch, 'metrics/precision(B)']:.4f}\")\n",
        "    print(f\"Best Recall: {df.loc[best_epoch, 'metrics/recall(B)']:.4f}\")\n",
        "else:\n",
        "    print(\"Results CSV not found. Training curves may not be available.\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
